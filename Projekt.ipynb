{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3343f13f",
   "metadata": {},
   "source": [
    "# Projekt PRIAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b553490",
   "metadata": {},
   "source": [
    "## Rozpoznawanie autora utworu literackiego na podstawie treści utworu z wykorzystaniem worka słów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1536703a",
   "metadata": {},
   "source": [
    "### Stanisław Maliński, Jan Stachurski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c325b8c9",
   "metadata": {},
   "source": [
    "Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e83dca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4ca9ad",
   "metadata": {},
   "source": [
    "Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760dae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/\"\n",
    "file_list = os.listdir(data_path)\n",
    "func = lambda  a : a.replace(\".txt\", \"\").split(\"-\")\n",
    "count_size = lambda a : os.stat(a).st_size\n",
    "data = [[func(title)[0], func(title)[1], data_path + title, count_size(data_path + title)] for title in file_list]\n",
    "df = pd.DataFrame(data, columns=[\"Author\", \"Name of The work\", \"FilePath\", \"FileSize\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f26f45",
   "metadata": {},
   "source": [
    "Przedstawiam zestaw uczący. Mamy tutaj pozycję kilku Polskich autorów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47b560c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   FileSize\n",
      "Author                     \n",
      "AdamMickiewicz       516084\n",
      "HenrykSienkiewicz    867390\n"
     ]
    }
   ],
   "source": [
    "print(df.drop(columns=[\"Name of The work\", \"FilePath\"]).groupby(\"Author\").sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f33f82",
   "metadata": {},
   "source": [
    "Wczytanie stop-słów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd973fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "delimeters = [\"\\\\n\", \"'\"]\n",
    "stop_words = []\n",
    "with open(\"./stopyPL.txt\", encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word = repr(line)\n",
    "        for c in delimeters:\n",
    "            word = word.replace(c, \"\")\n",
    "        stop_words.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f8afd",
   "metadata": {},
   "source": [
    "Projekt ten używa worka słów, który to przechowuje informacje na temat częstości występowania słów w danym dokumencie. Definiujemy tu dwie funckje jedna do standaryzacji słów tzn. usunięcia ewentualnych znaków graficznych takich jak kropka czy przecinek oraz ustawienie wielkości liter na małe aby słowa \"Który\" oraz \"który\" były zliczane jako to same słowo.\n",
    "Druga funkcja służy do budowania worka słów. Zlicza najpierw pojedyńcze przypadki wystąpień, a następnie zlicza częstość wystąpień danego słowa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "016f7a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_word(word):\n",
    "    word = word.lower()\n",
    "    special_char = [\".\", \",\", \"-\", \"?\", \"(\", \")\", \"!\", \"\\\\\", \"\\\"\", \":\", \";\", \"*\"]\n",
    "    for char in special_char:\n",
    "        word = word.replace(char, \"\")\n",
    "    return word\n",
    "\n",
    "def remove_stop_words(word):\n",
    "    pass\n",
    "\n",
    "def generate_word_bag(FileName, rmstops=True):\n",
    "    word_bag = {}\n",
    "    over_all_words = 0\n",
    "    with open(FileName, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            words = line.split()\n",
    "            words = [normalize_word(word) for word in words]\n",
    "            for word in words:\n",
    "                if word != '':\n",
    "                    over_all_words += 1\n",
    "                    if word in word_bag.keys():\n",
    "                        word_bag[word]['Count'] += 1\n",
    "                    else:\n",
    "                        word_bag[word] = {'Count':1, 'Frequent':1, 'Is stop word':False}\n",
    "                                    \n",
    "        f.close()\n",
    "    for word in word_bag.keys():\n",
    "        word_bag[word]['Frequent'] = word_bag[word]['Count'] / over_all_words\n",
    "    return word_bag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acc39f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W pliku: \"./data/AdamMickiewicz-Burza.txt\" Słowo: \"burza\" występowało z częstością: 9.62e-03\n"
     ]
    }
   ],
   "source": [
    "file = \"./data/AdamMickiewicz-Burza.txt\"\n",
    "dictionary = generate_word_bag(file)\n",
    "slowa = dictionary.keys()\n",
    "slowo = list(slowa)[2]\n",
    "\n",
    "print(\"W pliku: \\\"{}\\\" Słowo: \\\"{}\\\" występowało z częstością: {:.2e}\".format(file, slowo, dictionary[slowo]['Frequent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2fb1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def head(dictionary, start=0, end=None, step=1, fname=None):\n",
    "    words = list(dictionary.keys())\n",
    "    if end is None:\n",
    "        end = min(5, len(words))\n",
    "    if fname is not None:\n",
    "        print(\"W pliku: \\\"{}\\\"\".format(fname))\n",
    "    for word in words[start:end:step]:\n",
    "        print(\"Słowo: \\\"{}\\\" występowało z częstością: {:.2e}\".format(word,dictionary[word]['Frequent']), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bb7eadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W pliku: \"data/AdamMickiewicz-Dziady.txt\"\n",
      "Słowo: \"dziady\" występowało z częstością: 2.44e-03\n",
      "Słowo: \"poema\" występowało z częstością: 6.09e-04\n",
      "Słowo: \"część\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"ii\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"jest\" występowało z częstością: 2.13e-03\n",
      "Słowo: \"to\" występowało z częstością: 1.37e-02\n",
      "Słowo: \"nazwisko\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"uroczystości\" występowało z częstością: 6.09e-04\n",
      "Słowo: \"obchodzonej\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"dotąd\" występowało z częstością: 1.22e-03\n",
      "Słowo: \"między\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"pospólstwem\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"w\" występowało z częstością: 2.50e-02\n",
      "Słowo: \"wielu\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"powiatach\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"litwy\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"prus\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"i\" występowało z częstością: 2.62e-02\n",
      "Słowo: \"kurlandii\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"na\" występowało z częstością: 1.28e-02\n",
      "Słowo: \"pamiątkę\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"dziadów\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"czyli\" występowało z częstością: 2.13e-03\n",
      "Słowo: \"ogólności\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"zmarłych\" występowało z częstością: 6.09e-04\n",
      "Słowo: \"przodków\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"uroczystość\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"ta\" występowało z częstością: 1.52e-03\n",
      "Słowo: \"początkiem\" występowało z częstością: 3.05e-04\n",
      "Słowo: \"swoim\" występowało z częstością: 3.05e-04\n"
     ]
    }
   ],
   "source": [
    "file = df[\"FilePath\"][1]\n",
    "dictionary = generate_word_bag(file, rmstops=False)\n",
    "head(dictionary, end=30, fname=\"data/AdamMickiewicz-Dziady.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67a3c21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nie -> 98\n",
      "i -> 86\n",
      "w -> 82\n",
      "z -> 71\n",
      "a -> 48\n",
      "to -> 45\n",
      "się -> 45\n",
      "na -> 42\n",
      "guślarz -> 38\n",
      "chór -> 36\n"
     ]
    }
   ],
   "source": [
    "def show_most_frequent(dic ,threshold=0):\n",
    "    po_czestosci = dict(sorted(dic.items(), key=lambda x: int(x[1]['Count']), reverse = True))\n",
    "    for index, word in enumerate(po_czestosci.keys()):\n",
    "        if threshold == 0 and index < 10:\n",
    "            print(word + \" -> \" + str(po_czestosci[word]['Count']))\n",
    "        elif threshold == 0:\n",
    "            break\n",
    "        elif po_czestosci[word]['Count'] > threshold:\n",
    "            print(word + \" -> \" + str(po_czestosci[word]['Count']))\n",
    "        else:\n",
    "            break\n",
    "show_most_frequent(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19e862b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pierwszy słownik  Drugi słownik  Trzeci słownik\n",
      "1                 1              0               0\n",
      "2                 2              2               2\n",
      "3                 0              3               3\n",
      "4                 0              0               4\n",
      "7                 0              0               7\n"
     ]
    }
   ],
   "source": [
    "def merge_dics_to_df(dics, labels=None):\n",
    "    tab = []\n",
    "    word_found = []\n",
    "    for dic in dics:\n",
    "        for word in dic.keys():\n",
    "            if not word in word_found:\n",
    "                word_found.append(word)\n",
    "                rec = []\n",
    "                for dictionary in dics:\n",
    "                    if word in dictionary.keys():\n",
    "                        rec.append(dictionary[word])\n",
    "                    else:\n",
    "                        rec.append(0)\n",
    "                tab.append(rec)\n",
    "    \n",
    "    if labels is not None: \n",
    "        df = pd.DataFrame(tab, columns=labels, index=word_found)\n",
    "    else:\n",
    "        df = pd.DataFrame(tab)\n",
    "        \n",
    "    return df\n",
    "    \n",
    "df = merge_dics_to_df([{'1': 1, '2': 2}, \n",
    "                        {'3': 3, '2': 2}, \n",
    "                        {'3': 3, '2': 2, '4': 4, '7':7}], \n",
    "                       [\"Pierwszy słownik\", \"Drugi słownik\", \"Trzeci słownik\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b97c61bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pierwszy słownik  Drugi słownik  Trzeci słownik  w ilu       idf\n",
      "1                 1              0               0      1  1.098612\n",
      "2                 2              2               2      3  0.000000\n",
      "3                 0              3               3      2  0.405465\n",
      "4                 0              0               4      1  1.098612\n",
      "7                 0              0               7      1  1.098612\n"
     ]
    }
   ],
   "source": [
    "def tf_idf(data):   \n",
    "    ile_slow = data.count(0)[0]\n",
    "    tf = np.empty((ile_slow,len(data.columns)))\n",
    "    for i in range(0,len(data.columns)):\n",
    "        tf[:,i] = np.array(data.iloc[:,i]/data.sum()[i])\n",
    "                           \n",
    "    #print((data>0).head())\n",
    "\n",
    "    #print(np.array((data>0)*1).sum(axis=1))\n",
    "    \n",
    "    idf = np.log(len(data.columns)/np.array((data>0)*1).sum(axis=1))\n",
    "\n",
    "    data['w ilu'] = (np.array((data>0)*1).sum(axis=1)).T\n",
    "    data['idf'] = idf.T\n",
    "    \n",
    "tf_idf(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d4ec686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pierwszy słownik  Drugi słownik  Trzeci słownik  w ilu       idf\n",
      "2                 2              2               2      3  0.000000\n",
      "3                 0              3               3      2  0.405465\n"
     ]
    }
   ],
   "source": [
    "def drop_if(data, idf_threshold):\n",
    "    data = data[data.idf <= idf_threshold]\n",
    "    return data\n",
    "\n",
    "print(drop_if(df, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a3a5098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pierwszy słownik  Drugi słownik  Trzeci słownik  w ilu       idf\n",
      "2                 2              2               2      3  0.000000\n",
      "3                 0              3               3      2  0.405465\n"
     ]
    }
   ],
   "source": [
    "def drop_if(data, idf_threshold):\n",
    "    data = data[data.idf <= idf_threshold]\n",
    "    return data\n",
    "\n",
    "print(drop_if(df, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d57c8",
   "metadata": {},
   "source": [
    "Teraz musimy stworzyć model, który będzie klasyfikował do jakiego autora należy dany utwór."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8dd5b33a86443fe513679c02cd28a92e41225ac53964ff0e7afc55cbcc9ed7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
