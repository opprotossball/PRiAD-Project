{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c325b8c9",
   "metadata": {},
   "source": [
    "Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e83dca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4ca9ad",
   "metadata": {},
   "source": [
    "Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "760dae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(\"Dane\")\n",
    "func = lambda  a : a.replace(\".txt\", \"\").split(\"-\")\n",
    "count_size = lambda a : os.stat(a).st_size\n",
    "data = [[func(title)[0],func(title)[1], \"Dane/\" + title, count_size(\"Dane/\" + title)] for title in file_list]\n",
    "df = pd.DataFrame(data, columns=[\"Author\", \"Name of The work\", \"FilePath\", \"FileSize\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f26f45",
   "metadata": {},
   "source": [
    "Przedstawiam zestaw uczący. Mamy tutaj pozycję kilku Polskich autorów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "47b560c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  FileSize\n",
      "Author                    \n",
      "AdamMickiewicz      761551\n",
      "Juliusz Słowacki    329618\n"
     ]
    }
   ],
   "source": [
    "print(df.drop(columns=[\"Name of The work\", \"FilePath\"]).groupby(\"Author\").sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f768b1",
   "metadata": {},
   "source": [
    "Implementacje tablicy mieszającej pobraliśmy ze źródła: https://www.geeksforgeeks.org/hash-map-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f713696",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.hash_table = [[] for _ in range(self.size)]\n",
    "\n",
    "    def put(self, key, val):\n",
    "        hashed_key = hash(key) % self.size\n",
    "        bucket = self.hash_table[hashed_key]\n",
    "        found_key = False\n",
    "        for index, record in enumerate(bucket):\n",
    "            record_key, record_val = record\n",
    "            if record_key == key:\n",
    "                found_key = True\n",
    "                break\n",
    "        if found_key:\n",
    "            bucket[index] = (key, val)\n",
    "        else:\n",
    "            bucket.append((key, val))\n",
    "            \n",
    "    def get(self, key):\n",
    "        hashed_key = hash(key) % self.size\n",
    "        bucket = self.hash_table[hashed_key]\n",
    "        found_key = False\n",
    "        for index, record in enumerate(bucket):\n",
    "            record_key, record_val = record\n",
    "            if record_key == key:\n",
    "                found_key = True\n",
    "                break\n",
    "        if found_key:\n",
    "            return record_val\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def pop(self, key):\n",
    "        hashed_key = hash(key) % self.size\n",
    "        bucket = self.hash_table[hashed_key]\n",
    "        found_key = False\n",
    "        for index, record in enumerate(bucket):\n",
    "            record_key, record_val = record\n",
    "\n",
    "            if record_key == key:\n",
    "                found_key = True\n",
    "                break\n",
    "        if found_key:\n",
    "            bucket.pop(index)\n",
    "            return record_val\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f8afd",
   "metadata": {},
   "source": [
    "Projekt ten używa worka słów, który to przechowuje informacje na temat częstości występowania słów w danym dokumencie. Definiujemy tu dwie funckje jedna do standaryzacji słów tzn. usunięcia ewentualnych znaków graficznych takich jak kropka czy przecinek oraz ustawienie wielkości liter na małe aby słowa \"Który\" oraz \"który\" były zliczane jako to same słowo.\n",
    "Druga funkcja służy do budowania worka słów. Zlicza najpierw pojedyńcze przypadki wystąpień, a następnie zlicza częstość wystąpień danego słowa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "016f7a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W pliku: \"Dane/AdamMickiewicz-Burza.txt\" Słowo: \"na\" występowało z częstością: 0.0002883506343713956\n"
     ]
    }
   ],
   "source": [
    "def normalize_word(word):\n",
    "    word = word.lower()\n",
    "    special_char = [\".\", \",\", \"-\", \"?\", \"(\", \")\", \"!\", \"\\\\\", \"\\\"\", \":\", \";\"]\n",
    "    for char in special_char:\n",
    "        word = word.replace(char, \"\")\n",
    "    return word\n",
    "\n",
    "def generate_word_bag(FileName):\n",
    "    word_bag = HashTable(5000)\n",
    "    over_all_words = 0\n",
    "    every_word = []\n",
    "    with open(FileName, \"r\") as f:\n",
    "        for line in f:\n",
    "            words = line.split()\n",
    "            words = [normalize_word(word) for word in words]\n",
    "            for word in words:\n",
    "                if word != '':\n",
    "                    over_all_words += 1\n",
    "                    counter = word_bag.pop(word)\n",
    "                    if counter != None:\n",
    "                        word_bag.put(word, counter + 1)\n",
    "                        every_word.append(word)\n",
    "                    else:\n",
    "                        counter = 0\n",
    "                        word_bag.put(word, 1)\n",
    "        f.close()\n",
    "    for word in every_word:\n",
    "        counter = word_bag.pop(word)\n",
    "        word_bag.put(word, counter/over_all_words)\n",
    "    return word_bag, every_word\n",
    "        \n",
    "file = \"Dane/AdamMickiewicz-Burza.txt\"\n",
    "dictionary, words = generate_word_bag(file)\n",
    "print(\"W pliku: \\\"\", file,\"\\\" Słowo: \\\"\", words[4],\"\\\" występowało z częstością: \", dictionary.get(words[4]), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d57c8",
   "metadata": {},
   "source": [
    "Teraz musimy stworzyć model, który będzie klasyfikował do jakiego autora należy dany utwór."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
