{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3343f13f",
   "metadata": {},
   "source": [
    "# Projekt PRIAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b553490",
   "metadata": {},
   "source": [
    "## Rozpoznawanie autora utworu literackiego na podstawie treści utworu z wykorzystaniem worka słów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1536703a",
   "metadata": {},
   "source": [
    "### Stanisław Maliński, Jan Stachurski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c325b8c9",
   "metadata": {},
   "source": [
    "Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e83dca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4ca9ad",
   "metadata": {},
   "source": [
    "Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "760dae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/\"\n",
    "file_list = os.listdir(data_path)\n",
    "func = lambda  a : a.replace(\".txt\", \"\").split(\"-\")\n",
    "count_size = lambda a : os.stat(a).st_size\n",
    "data = [[func(title)[0], func(title)[1], data_path + title, count_size(data_path + title)] for title in file_list]\n",
    "files = pd.DataFrame(data, columns=['Author', 'Name of The work', 'FilePath', 'FileSize'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f26f45",
   "metadata": {},
   "source": [
    "Przedstawiam zestaw uczący. Mamy tutaj pozycję kilku Polskich autorów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47b560c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   FileSize\n",
      "Author                     \n",
      "AdamMickiewicz       761572\n",
      "HenrykSienkiewicz    867390\n",
      "Juliusz Słowacki     329618\n"
     ]
    }
   ],
   "source": [
    "print(files.drop(columns=['Name of The work', 'FilePath']).groupby('Author').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f33f82",
   "metadata": {},
   "source": [
    "Wczytanie stop-słów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd973fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_words():\n",
    "    delimeters = [\"\\\\n\", \"'\"]\n",
    "    stop_words = []\n",
    "    with open(\"./stopyPL.txt\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word = repr(line)\n",
    "            for c in delimeters:\n",
    "                word = word.replace(c, \"\")\n",
    "            stop_words.append(word)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f8afd",
   "metadata": {},
   "source": [
    "Projekt ten używa worka słów, który to przechowuje informacje na temat częstości występowania słów w danym dokumencie. Definiujemy tu dwie funckje jedna do standaryzacji słów tzn. usunięcia ewentualnych znaków graficznych takich jak kropka czy przecinek oraz ustawienie wielkości liter na małe aby słowa \"Który\" oraz \"który\" były zliczane jako to same słowo.\n",
    "Druga funkcja służy do budowania worka słów. Zlicza najpierw pojedyńcze przypadki wystąpień, a następnie zlicza częstość wystąpień danego słowa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "016f7a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_word(word):\n",
    "    word = word.lower()\n",
    "    special_char = [\".\", \",\", \"-\", \"?\", \"(\", \")\", \"!\", \"\\\\\", \"\\\"\", \":\", \";\", \"*\"]\n",
    "    for char in special_char:\n",
    "        word = word.replace(char, \"\")\n",
    "    return word\n",
    "\n",
    "# 0 - generete bag with all words, 1 - bag without stopwords, 2 - bag with only stopwords\n",
    "def generate_word_bag(FileName, mode=0):\n",
    "    stop_word = get_stop_words()\n",
    "    word_bag = {}\n",
    "    words_in_bag = 0\n",
    "    with open(FileName, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            words = line.split()\n",
    "            words = [normalize_word(word) for word in words]\n",
    "            for word in words:\n",
    "                if word != '':\n",
    "                    if (mode==0) or (mode==1 and not word in stop_word) or (mode==2 and word in stop_word):\n",
    "                        words_in_bag += 1\n",
    "                        if word in word_bag.keys():\n",
    "                            word_bag[word]['Count'] += 1\n",
    "                        else:\n",
    "                            word_bag[word] = {'Count':1, 'Frequent':1, 'Is stop word': word in stop_word}\n",
    "                                    \n",
    "        f.close()\n",
    "    for word in word_bag.keys():\n",
    "        word_bag[word]['Frequent'] = word_bag[word]['Count'] / words_in_bag\n",
    "    return word_bag                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acc39f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W pliku: \"./data/AdamMickiewicz-Burza.txt\" Słowo: \"burza\" występowało z częstością: 9.62e-03\n"
     ]
    }
   ],
   "source": [
    "file = \"./data/AdamMickiewicz-Burza.txt\"\n",
    "dictionary = generate_word_bag(file)\n",
    "slowa = dictionary.keys()\n",
    "slowo = list(slowa)[2]\n",
    "\n",
    "print(\"W pliku: \\\"{}\\\" Słowo: \\\"{}\\\" występowało z częstością: {:.2e}\".format(file, slowo, dictionary[slowo]['Frequent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2fb1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def head(dictionary, start=0, end=None, step=1, fname=None):\n",
    "    words = list(dictionary.keys())\n",
    "    if end is None:\n",
    "        end = min(5, len(words))\n",
    "    if fname is not None:\n",
    "        print(\"W pliku: \\\"{}\\\"\".format(fname))\n",
    "    for word in words[start:end:step]:\n",
    "        print(\"Słowo: \\\"{}\\\" występowało z częstością: {:.2e}\".format(word,dictionary[word]['Frequent']), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bb7eadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W pliku: \"data/AdamMickiewicz-Dziady.txt\"\n",
      "Słowo: \"w\" występowało z częstością: 2.07e-01\n",
      "Słowo: \"już\" występowało z częstością: 3.45e-02\n",
      "Słowo: \"z\" występowało z częstością: 1.72e-01\n",
      "Słowo: \"się\" występowało z częstością: 1.38e-01\n",
      "Słowo: \"i\" występowało z częstością: 1.72e-01\n",
      "Słowo: \"jak\" występowało z częstością: 6.90e-02\n",
      "Słowo: \"nad\" występowało z częstością: 3.45e-02\n",
      "Słowo: \"a\" występowało z częstością: 6.90e-02\n",
      "Słowo: \"jego\" występowało z częstością: 3.45e-02\n",
      "Słowo: \"dla\" występowało z częstością: 3.45e-02\n"
     ]
    }
   ],
   "source": [
    "file = df[\"FilePath\"][1]\n",
    "dictionary = generate_word_bag(file, 2)\n",
    "head(dictionary, end=10, fname=\"data/AdamMickiewicz-Dziady.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67a3c21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w -> 6\n",
      "z -> 5\n",
      "i -> 5\n",
      "się -> 4\n",
      "jak -> 2\n",
      "a -> 2\n",
      "już -> 1\n",
      "nad -> 1\n",
      "jego -> 1\n",
      "dla -> 1\n"
     ]
    }
   ],
   "source": [
    "def show_most_frequent(dic ,threshold=0):\n",
    "    po_czestosci = dict(sorted(dic.items(), key=lambda x: int(x[1]['Count']), reverse = True))\n",
    "    for index, word in enumerate(po_czestosci.keys()):\n",
    "        if threshold == 0 and index < 10:\n",
    "            print(word + \" -> \" + str(po_czestosci[word]['Count']))\n",
    "        elif threshold == 0:\n",
    "            break\n",
    "        elif po_czestosci[word]['Count'] > threshold:\n",
    "            print(word + \" -> \" + str(po_czestosci[word]['Count']))\n",
    "        else:\n",
    "            break\n",
    "show_most_frequent(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ee410",
   "metadata": {},
   "source": [
    "Mamy już mały warsztat narzędzi do analizy utworów. Stworzymy teraz parę funckji, które pozwolą nam zgrabnie manipulować macierzą danych. \n",
    "merge_dics_to_df - łączy worki słów w ramkę danych, którą później wykorzystamy do nauki klasyfikatora.\n",
    "tf_idf - analiza TF_IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19e862b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  1  2  3  4  7\n",
      "Pierwszy słownik  1  2  0  0  0\n",
      "Drugi słownik     0  2  3  0  0\n",
      "Trzeci słownik    0  2  3  4  7\n"
     ]
    }
   ],
   "source": [
    "def merge_dics_to_df(dics, labels=None, transform=lambda x:x):\n",
    "    tab = []\n",
    "    word_found = []\n",
    "    for dic in dics:\n",
    "        for word in dic.keys():\n",
    "            if not word in word_found:\n",
    "                word_found.append(word)\n",
    "                rec = []\n",
    "                for dictionary in dics:\n",
    "                    if word in dictionary.keys():\n",
    "                        rec.append(transform(dictionary[word]))\n",
    "                    else:\n",
    "                        rec.append(0)\n",
    "                tab.append(rec)\n",
    "    \n",
    "    if labels is not None: \n",
    "        df = pd.DataFrame(tab, columns=labels, index=word_found)\n",
    "    else:\n",
    "        df = pd.DataFrame(tab)\n",
    "        \n",
    "    return df.T\n",
    "    \n",
    "df = merge_dics_to_df([{'1': 1, '2': 2}, \n",
    "                        {'3': 3, '2': 2}, \n",
    "                        {'3': 3, '2': 2, '4': 4, '7':7}], \n",
    "                       [\"Pierwszy słownik\", \"Drugi słownik\", \"Trzeci słownik\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b97c61bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  1  2  3  4  7  w ilu       idf\n",
      "Pierwszy słownik  1  2  0  0  0      2  0.916291\n",
      "Drugi słownik     0  2  3  0  0      2  0.916291\n",
      "Trzeci słownik    0  2  3  4  7      4  0.223144\n"
     ]
    }
   ],
   "source": [
    "def tf_idf(data):   \n",
    "    ile_slow = data.count(0)[0]\n",
    "    tf = np.empty((ile_slow,len(data.columns)))\n",
    "    for i in range(0,len(data.columns)):\n",
    "        tf[:,i] = np.array(data.iloc[:,i]/data.sum()[i])\n",
    "                           \n",
    "    #print((data>0).head())\n",
    "\n",
    "    #print(np.array((data>0)*1).sum(axis=1))\n",
    "    \n",
    "    idf = np.log(len(data.columns)/np.array((data>0)*1).sum(axis=1))\n",
    "\n",
    "    data['w ilu'] = (np.array((data>0)*1).sum(axis=1)).T\n",
    "    data['idf'] = idf.T\n",
    "    \n",
    "tf_idf(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5d4ec686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  1  2  3  4  7  w ilu       idf\n",
      "Pierwszy słownik  1  2  0  0  0      2  0.916291\n",
      "Drugi słownik     0  2  3  0  0      2  0.916291\n",
      "Trzeci słownik    0  2  3  4  7      4  0.223144\n"
     ]
    }
   ],
   "source": [
    "def drop_if(data, idf_threshold):\n",
    "    data = data[data.idf <= idf_threshold]\n",
    "    return data\n",
    "\n",
    "print(drop_if(df, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a3a5098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  1  2  3  4  7  w ilu       idf\n",
      "Pierwszy słownik  1  2  0  0  0      2  0.916291\n",
      "Drugi słownik     0  2  3  0  0      2  0.916291\n",
      "Trzeci słownik    0  2  3  4  7      4  0.223144\n"
     ]
    }
   ],
   "source": [
    "def drop_if(data, idf_threshold):\n",
    "    data = data[data.idf <= idf_threshold]\n",
    "    return data\n",
    "\n",
    "print(drop_if(df, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d57c8",
   "metadata": {},
   "source": [
    "Teraz musimy stworzyć model, który będzie klasyfikował do jakiego autora należy dany utwór."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11331428",
   "metadata": {},
   "source": [
    "Wczytanie obliczenie słowników dla wszystkich utworów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b755729",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_bags = []\n",
    "index = []\n",
    "labels = []\n",
    "\n",
    "for path, name, label in zip(files['FilePath'], files['Name of The work'], files['Author']):\n",
    "    word_bags.append(generate_word_bag(path, mode=2))\n",
    "    index.append(name)\n",
    "    labels.append(label)\n",
    "    \n",
    "df = merge_dics_to_df(word_bags, index, lambda x:x['Frequent'])\n",
    "df['label'] = labels\n",
    "                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "65ec1fea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>na</th>\n",
       "      <th>jak</th>\n",
       "      <th>to</th>\n",
       "      <th>w</th>\n",
       "      <th>się</th>\n",
       "      <th>o</th>\n",
       "      <th>i</th>\n",
       "      <th>za</th>\n",
       "      <th>sobą</th>\n",
       "      <th>lecz</th>\n",
       "      <th>...</th>\n",
       "      <th>bowiem</th>\n",
       "      <th>poza</th>\n",
       "      <th>dużo</th>\n",
       "      <th>dokąd</th>\n",
       "      <th>możliwe</th>\n",
       "      <th>gdziekolwiek</th>\n",
       "      <th>powinno</th>\n",
       "      <th>acz</th>\n",
       "      <th>nia</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ajudah</th>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AdamMickiewicz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ałuszta w dzień</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AdamMickiewicz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ałuszta w nocy</th>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AdamMickiewicz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bajdary</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AdamMickiewicz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bakczysaraj</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AdamMickiewicz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       na       jak        to         w       się         o  \\\n",
       "Ajudah           0.129032  0.096774  0.064516  0.129032  0.096774  0.064516   \n",
       "Ałuszta w dzień  0.034483  0.068966  0.000000  0.206897  0.137931  0.000000   \n",
       "Ałuszta w nocy   0.130435  0.043478  0.000000  0.086957  0.130435  0.000000   \n",
       "Bajdary          0.083333  0.083333  0.000000  0.166667  0.083333  0.000000   \n",
       "Bakczysaraj      0.105263  0.000000  0.052632  0.105263  0.052632  0.105263   \n",
       "\n",
       "                        i        za      sobą      lecz  ...  bowiem  poza  \\\n",
       "Ajudah           0.096774  0.064516  0.064516  0.032258  ...     0.0   0.0   \n",
       "Ałuszta w dzień  0.172414  0.000000  0.000000  0.000000  ...     0.0   0.0   \n",
       "Ałuszta w nocy   0.130435  0.000000  0.000000  0.000000  ...     0.0   0.0   \n",
       "Bajdary          0.111111  0.000000  0.000000  0.000000  ...     0.0   0.0   \n",
       "Bakczysaraj      0.263158  0.000000  0.000000  0.000000  ...     0.0   0.0   \n",
       "\n",
       "                 dużo  dokąd  możliwe  gdziekolwiek  powinno  acz  nia  \\\n",
       "Ajudah            0.0    0.0      0.0           0.0      0.0  0.0  0.0   \n",
       "Ałuszta w dzień   0.0    0.0      0.0           0.0      0.0  0.0  0.0   \n",
       "Ałuszta w nocy    0.0    0.0      0.0           0.0      0.0  0.0  0.0   \n",
       "Bajdary           0.0    0.0      0.0           0.0      0.0  0.0  0.0   \n",
       "Bakczysaraj       0.0    0.0      0.0           0.0      0.0  0.0  0.0   \n",
       "\n",
       "                          label  \n",
       "Ajudah           AdamMickiewicz  \n",
       "Ałuszta w dzień  AdamMickiewicz  \n",
       "Ałuszta w nocy   AdamMickiewicz  \n",
       "Bajdary          AdamMickiewicz  \n",
       "Bakczysaraj      AdamMickiewicz  \n",
       "\n",
       "[5 rows x 282 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f174aa3e",
   "metadata": {},
   "source": [
    "Jak widzimy mamy już ramkę danych, w której każdym obiektem jest dzieło a wektorem atrybutów jest częstość wystąpień poszczególnych słów w każdym z dzieł. Dodaliśmy również atrybuty decyzyjny czyli nazwisko autora danego dzieła."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fd7542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8dd5b33a86443fe513679c02cd28a92e41225ac53964ff0e7afc55cbcc9ed7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
