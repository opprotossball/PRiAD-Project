{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c325b8c9",
   "metadata": {},
   "source": [
    "Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e83dca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4ca9ad",
   "metadata": {},
   "source": [
    "Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "760dae10",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Nie można odnaleźć określonego pliku: './dataAdamMickiewicz-Burza.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [61], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m  a : a\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m count_size \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m a : os\u001b[39m.\u001b[39mstat(a)\u001b[39m.\u001b[39mst_size\n\u001b[1;32m----> 5\u001b[0m data \u001b[39m=\u001b[39m [[func(title)[\u001b[39m0\u001b[39m], func(title)[\u001b[39m1\u001b[39m], data_path \u001b[39m+\u001b[39m title, count_size(data_path \u001b[39m+\u001b[39m title)] \u001b[39mfor\u001b[39;00m title \u001b[39min\u001b[39;00m file_list]\n\u001b[0;32m      6\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data, columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mAuthor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mName of The work\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFilePath\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFileSize\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn [61], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m  a : a\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m count_size \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m a : os\u001b[39m.\u001b[39mstat(a)\u001b[39m.\u001b[39mst_size\n\u001b[1;32m----> 5\u001b[0m data \u001b[39m=\u001b[39m [[func(title)[\u001b[39m0\u001b[39m], func(title)[\u001b[39m1\u001b[39m], data_path \u001b[39m+\u001b[39m title, count_size(data_path \u001b[39m+\u001b[39;49m title)] \u001b[39mfor\u001b[39;00m title \u001b[39min\u001b[39;00m file_list]\n\u001b[0;32m      6\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data, columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mAuthor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mName of The work\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFilePath\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFileSize\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn [61], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m      2\u001b[0m file_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(data_path)\n\u001b[0;32m      3\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m  a : a\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m count_size \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m a : os\u001b[39m.\u001b[39;49mstat(a)\u001b[39m.\u001b[39mst_size\n\u001b[0;32m      5\u001b[0m data \u001b[39m=\u001b[39m [[func(title)[\u001b[39m0\u001b[39m], func(title)[\u001b[39m1\u001b[39m], data_path \u001b[39m+\u001b[39m title, count_size(data_path \u001b[39m+\u001b[39m title)] \u001b[39mfor\u001b[39;00m title \u001b[39min\u001b[39;00m file_list]\n\u001b[0;32m      6\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data, columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mAuthor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mName of The work\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFilePath\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFileSize\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Nie można odnaleźć określonego pliku: './dataAdamMickiewicz-Burza.txt'"
     ]
    }
   ],
   "source": [
    "data_path = \"./data\"\n",
    "file_list = os.listdir(data_path)\n",
    "func = lambda  a : a.replace(\".txt\", \"\").split(\"-\")\n",
    "count_size = lambda a : os.stat(a).st_size\n",
    "data = [[func(title)[0], func(title)[1], data_path + title, count_size(data_path + title)] for title in file_list]\n",
    "df = pd.DataFrame(data, columns=[\"Author\", \"Name of The work\", \"FilePath\", \"FileSize\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f26f45",
   "metadata": {},
   "source": [
    "Przedstawiam zestaw uczący. Mamy tutaj pozycję kilku Polskich autorów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b560c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   FileSize\n",
      "Author                     \n",
      "AdamMickiewicz       516084\n",
      "HenrykSienkiewicz    867390\n",
      "              Author    Name of The work  \\\n",
      "0     AdamMickiewicz               Burza   \n",
      "1     AdamMickiewicz              Dziady   \n",
      "2     AdamMickiewicz          PanTadeusz   \n",
      "3  HenrykSienkiewicz  OgniemIMieczemTom1   \n",
      "\n",
      "                                        FilePath  FileSize  \n",
      "0                  data/AdamMickiewicz-Burza.txt       742  \n",
      "1                 data/AdamMickiewicz-Dziady.txt     23305  \n",
      "2             data/AdamMickiewicz-PanTadeusz.txt    492037  \n",
      "3  data/HenrykSienkiewicz-OgniemIMieczemTom1.txt    867390  \n"
     ]
    }
   ],
   "source": [
    "print(df.drop(columns=[\"Name of The work\", \"FilePath\"]).groupby(\"Author\").sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f768b1",
   "metadata": {},
   "source": [
    "Implementacje tablicy mieszającej pobraliśmy ze źródła: https://www.geeksforgeeks.org/hash-map-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f713696",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.hash_table = [[] for _ in range(self.size)]\n",
    "\n",
    "    def put(self, key, val):\n",
    "        hashed_key = hash(key) % self.size\n",
    "        bucket = self.hash_table[hashed_key]\n",
    "        found_key = False\n",
    "        for index, record in enumerate(bucket):\n",
    "            record_key, record_val = record\n",
    "            if record_key == key:\n",
    "                found_key = True\n",
    "                break\n",
    "        if found_key:\n",
    "            bucket[index] = (key, val)\n",
    "        else:\n",
    "            bucket.append((key, val))\n",
    "            \n",
    "    def get(self, key):\n",
    "        hashed_key = hash(key) % self.size\n",
    "        bucket = self.hash_table[hashed_key]\n",
    "        found_key = False\n",
    "        for index, record in enumerate(bucket):\n",
    "            record_key, record_val = record\n",
    "            if record_key == key:\n",
    "                found_key = True\n",
    "                break\n",
    "        if found_key:\n",
    "            return record_val\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def pop(self, key):\n",
    "        hashed_key = hash(key) % self.size\n",
    "        bucket = self.hash_table[hashed_key]\n",
    "        found_key = False\n",
    "        for index, record in enumerate(bucket):\n",
    "            record_key, record_val = record\n",
    "\n",
    "            if record_key == key:\n",
    "                found_key = True\n",
    "                break\n",
    "        if found_key:\n",
    "            bucket.pop(index)\n",
    "            return record_val\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57f33f82",
   "metadata": {},
   "source": [
    "Wczytanie stop-słów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd973fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "delimeters = [\"\\\\n\", \"'\"]\n",
    "stop_words = HashTable(350)\n",
    "with open(\"./stopyPL.txt\", encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word = repr(line)\n",
    "        for c in delimeters:\n",
    "            word = word.replace(c, \"\")\n",
    "        if word:\n",
    "            stop_words.put(word, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f8afd",
   "metadata": {},
   "source": [
    "Projekt ten używa worka słów, który to przechowuje informacje na temat częstości występowania słów w danym dokumencie. Definiujemy tu dwie funckje jedna do standaryzacji słów tzn. usunięcia ewentualnych znaków graficznych takich jak kropka czy przecinek oraz ustawienie wielkości liter na małe aby słowa \"Który\" oraz \"który\" były zliczane jako to same słowo.\n",
    "Druga funkcja służy do budowania worka słów. Zlicza najpierw pojedyńcze przypadki wystąpień, a następnie zlicza częstość wystąpień danego słowa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f7a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_word(word):\n",
    "    word = word.lower()\n",
    "    special_char = [\".\", \",\", \"-\", \"?\", \"(\", \")\", \"!\", \"\\\\\", \"\\\"\", \":\", \";\", \"*\"]\n",
    "    for char in special_char:\n",
    "        word = word.replace(char, \"\")\n",
    "    return word\n",
    "\n",
    "def remove_stop_words(word):\n",
    "    pass\n",
    "\n",
    "def generate_word_bag(FileName, rmstops=True):\n",
    "    word_bag = HashTable(5000)\n",
    "    over_all_words = 0\n",
    "    every_word = []\n",
    "    with open(FileName, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            words = line.split()\n",
    "            words = [normalize_word(word) for word in words]\n",
    "            for word in words:\n",
    "                if word != '':\n",
    "                    if rmstops and stop_words.get(word) is not None:\n",
    "                        continue\n",
    "                    over_all_words += 1\n",
    "                    counter = word_bag.pop(word)\n",
    "                    if counter is not None:\n",
    "                        word_bag.put(word, counter + 1)\n",
    "                        every_word.append(word)\n",
    "                    else:\n",
    "                        word_bag.put(word, 1)\n",
    "        f.close()\n",
    "    for word in every_word:\n",
    "        counter = word_bag.pop(word)\n",
    "        word_bag.put(word, counter/over_all_words)\n",
    "    return word_bag, every_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d2fb1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def head(words, dictionary, start=0, end=None, step=1, fname=None):\n",
    "    if end is None:\n",
    "        end = min(5, len(words))\n",
    "    if fname is not None:\n",
    "        print(\"W pliku: \\\"\" + fname + \"\\\"\")\n",
    "    for word in words[start:end:step]:\n",
    "        print(\"Słowo: \\\"\", word, \"\\\" występowało z częstością: \", dictionary.get(word), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9bb7eadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W pliku: \"data/AdamMickiewicz-Dziady.txt\"\n",
      "Słowo: \"dziady\" występowało z częstością: 5.116493114424868e-23\n",
      "Słowo: \"dziady\" występowało z częstością: 5.116493114424868e-23\n",
      "Słowo: \"dziady\" występowało z częstością: 5.116493114424868e-23\n",
      "Słowo: \"zwyczaj\" występowało z częstością: 0.0009718172983479105\n",
      "Słowo: \"zmarłych\" występowało z częstością: 0.0009718172983479105\n",
      "Słowo: \"czasów\" występowało z częstością: 0.0009718172983479105\n",
      "Słowo: \"dotąd\" występowało z częstością: 4.589061522683342e-10\n",
      "Słowo: \"dziady\" występowało z częstością: 5.116493114424868e-23\n",
      "Słowo: \"uroczystości\" występowało z częstością: 0.0009718172983479105\n",
      "Słowo: \"pospólstwo\" występowało z częstością: 0.0009718172983479105\n",
      "Słowo: \"obrzędy\" występowało z częstością: 7.083216460261739e-07\n",
      "Słowo: \"niegdyś\" występowało z częstością: 4.589061522683342e-10\n",
      "Słowo: \"pewne\" występowało z częstością: 0.0009718172983479105\n",
      "Słowo: \"poema\" występowało z częstością: 0.0009718172983479105\n",
      "Słowo: \"guślarz\" występowało z częstością: 9.600744028334933e-122\n",
      "Słowo: \"—\" występowało z częstością: 4.589061522683342e-10\n",
      "Słowo: \"—\" występowało z częstością: 4.589061522683342e-10\n",
      "Słowo: \"/\" występowało z częstością: 3.7917446905450595e-82\n",
      "Słowo: \"are\" występowało z częstością: 0.0009718172983479105\n",
      "Słowo: \"in\" występowało z częstością: 0.0009718172983479105\n",
      "Słowo: \"chór\" występowało z częstością: 3.8522506387097135e-115\n",
      "Słowo: \"wszędzie\" występowało z częstością: 4.33248365834167e-59\n",
      "Słowo: \"guślarz\" występowało z częstością: 9.600744028334933e-122\n",
      "Słowo: \"żadnej\" występowało z częstością: 0.0009718172983479105\n",
      "Słowo: \"starzec\" występowało z częstością: 9.213524975800582e-20\n",
      "Słowo: \"chór\" występowało z częstością: 3.8522506387097135e-115\n",
      "Słowo: \"ciemno\" występowało z częstością: 2.7969167899552855e-26\n",
      "Słowo: \"wszędzie\" występowało z częstością: 4.33248365834167e-59\n",
      "Słowo: \"głucho\" występowało z częstością: 8.071216203352988e-33\n",
      "Słowo: \"wszędzie\" występowało z częstością: 4.33248365834167e-59\n"
     ]
    }
   ],
   "source": [
    "file = df[\"FilePath\"][1]\n",
    "dictionary, words = generate_word_bag(file)\n",
    "head(words, dictionary, end=30, fname=\"data/AdamMickiewicz-Dziady.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d57c8",
   "metadata": {},
   "source": [
    "Teraz musimy stworzyć model, który będzie klasyfikował do jakiego autora należy dany utwór."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8dd5b33a86443fe513679c02cd28a92e41225ac53964ff0e7afc55cbcc9ed7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
